{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "finance_df = pd.read_csv('./Dataset/Monthly.csv')\n",
    "energy_df = pd.read_csv('./Dataset/Hourly.csv')\n",
    "environment_df = pd.read_csv('./Dataset/Daily.csv')\n",
    "\n",
    "# Data cleaning\n",
    "def clean_data(df):\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "clean_data(finance_df)\n",
    "clean_data(energy_df)\n",
    "clean_data(environment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization/Standardization\n",
    "scaler = MinMaxScaler()\n",
    "finance_df[['open', 'high', 'low', 'close']] = scaler.fit_transform(finance_df[['open', 'high', 'low', 'close']])\n",
    "energy_df['AEP_MW'] = scaler.fit_transform(energy_df[['AEP_MW']])\n",
    "environment_df['value'] = scaler.fit_transform(environment_df[['value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationarization\n",
    "def stationarize_data(data):\n",
    "    return data.diff().dropna()\n",
    "\n",
    "finance_df['close_diff'] = stationarize_data(finance_df['close'])\n",
    "energy_df['AEP_MW_diff'] = stationarize_data(energy_df['AEP_MW'])\n",
    "environment_df['value_diff'] = stationarize_data(environment_df['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ARIMA model\n",
    "def fit_arima(data):\n",
    "    model = ARIMA(data.values, order=(5,1,0))\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=5)[0]  # Forecast next 5 values\n",
    "    return forecast\n",
    "\n",
    "finance_forecast = fit_arima(finance_df['close'])\n",
    "energy_forecast = fit_arima(energy_df['AEP_MW'])\n",
    "environment_forecast = fit_arima(environment_df['value'])\n",
    "\n",
    "\n",
    "# ANN model\n",
    "def build_ann(X_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=8, verbose=0)\n",
    "    return model\n",
    "\n",
    "def evaluate_ann(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "# Hybrid model integration\n",
    "def integrate_models(arima_forecast, ann_model):\n",
    "    arima_forecast = arima_forecast.reshape(-1, 1)\n",
    "    ann_residuals = ann_model.predict(arima_forecast)\n",
    "    integrated_predictions = arima_forecast + ann_residuals\n",
    "    return integrated_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [33884041, 5821]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m finance_forecast \u001b[38;5;241m=\u001b[39m finance_forecast\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Split data into features (X) and target variable (y)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinance_forecast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Build ANN model\u001b[39;00m\n\u001b[0;32m     11\u001b[0m ann_model \u001b[38;5;241m=\u001b[39m build_ann(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2614\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2618\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2619\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:455\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 455\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [33884041, 5821]"
     ]
    }
   ],
   "source": [
    "# Repeat the forecast value to match the length of finance_df['close']\n",
    "# finance_forecast = np.repeat(finance_forecast, len(finance_df['close']))\n",
    "finance_forecast_extended = np.repeat(finance_forecast[-1], len(finance_df['close']))\n",
    "# Reshape finance_forecast to match the shape of y\n",
    "finance_forecast = finance_forecast.reshape(-1, 1)\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(finance_forecast, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build ANN model\n",
    "ann_model = build_ann(X_train, y_train)\n",
    "\n",
    "# Evaluate ANN model\n",
    "ann_evaluation = evaluate_ann(ann_model, X_test, y_test)\n",
    "\n",
    "# Integrate models\n",
    "integrated_predictions = integrate_models(finance_forecast, ann_model)\n",
    "\n",
    "# Evaluate overall forecast accuracy\n",
    "print(\"Mean Squared Error of ARIMA model:\", mean_squared_error(finance_df['close'], finance_forecast))\n",
    "print(\"Mean Squared Error of Integrated Model:\", mean_squared_error(finance_df['close'], integrated_predictions.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date      open      high       low     close  close_diff\n",
      "0       1/3/2000  0.191497  0.189829  0.187582  0.189001         NaN\n",
      "1       1/4/2000  0.188096  0.184304  0.177631  0.175457   -0.013544\n",
      "2       1/5/2000  0.174570  0.174130  0.172829  0.176110    0.000653\n",
      "3       1/6/2000  0.175222  0.173798  0.176335  0.176436    0.000325\n",
      "4       1/7/2000  0.175547  0.180969  0.178433  0.185664    0.009228\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "5816  02/14/2023  0.835692  0.840215  0.833458  0.839703   -0.000282\n",
      "5817  02/15/2023  0.833946  0.837387  0.835638  0.842487    0.002784\n",
      "5818  02/16/2023  0.832795  0.834581  0.832116  0.828606   -0.013881\n",
      "5819  02/17/2023  0.823821  0.821235  0.822017  0.825858   -0.002748\n",
      "5820  02/21/2023  0.817668  0.814163  0.809190  0.806016   -0.019842\n",
      "\n",
      "[5821 rows x 6 columns]\n",
      "Forcast:  [[0.80791096]]\n",
      "0       0.189001\n",
      "1       0.175457\n",
      "2       0.176110\n",
      "3       0.176436\n",
      "4       0.185664\n",
      "          ...   \n",
      "5816    0.839703\n",
      "5817    0.842487\n",
      "5818    0.828606\n",
      "5819    0.825858\n",
      "5820    0.806016\n",
      "Name: close, Length: 5821, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(finance_df)\n",
    "print(\"Forcast: \", finance_forecast)\n",
    "print(finance_df['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Scale input features\u001b[39;00m\n\u001b[0;32m     37\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m---> 38\u001b[0m scaled_input_features \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Define ANN model\u001b[39;00m\n\u001b[0;32m     41\u001b[0m ann_model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     42\u001b[0m     Dense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(scaled_input_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],)),\n\u001b[0;32m     43\u001b[0m     Dense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     44\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     45\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:434\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:472\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    469\u001b[0m     )\n\u001b[0;32m    471\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 472\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    480\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    516\u001b[0m ):\n\u001b[0;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:440\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m       should set `reset=False`.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[1;32m--> 440\u001b[0m     feature_names_in \u001b[38;5;241m=\u001b[39m \u001b[43m_get_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m feature_names_in\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2021\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[0;32m   2020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[1;32m-> 2021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2022\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names are only supported if all input features have string names, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2023\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as feature name / column name types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2026\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2027\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, or convert them all to a non-string data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2028\u001b[0m     )\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[0;32m   2031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load finance data\n",
    "finance_df = pd.read_csv('./Dataset/Monthly.csv')\n",
    "finance_df['Date'] = pd.to_datetime(finance_df['Date'])\n",
    "finance_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Load energy data\n",
    "energy_df = pd.read_csv('./Dataset/Hourly.csv')\n",
    "energy_df['Datetime'] = pd.to_datetime(energy_df['Datetime'])\n",
    "energy_df.set_index('Datetime', inplace=True)\n",
    "\n",
    "# Load environment data\n",
    "environment_df = pd.read_csv('./Dataset/Daily.csv')\n",
    "environment_df['date'] = pd.to_datetime(environment_df['date'])\n",
    "environment_df.set_index('date', inplace=True)\n",
    "\n",
    "# Train ARIMA model\n",
    "arima_model = ARIMA(finance_df['close'], order=(2, 1, 2))\n",
    "arima_result = arima_model.fit()\n",
    "arima_forecast = arima_result.forecast(steps=10)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = finance_df['close'] - arima_result.fittedvalues\n",
    "energy_df.reset_index(inplace=True)\n",
    "environment_df.reset_index(inplace=True)\n",
    "# Combine input features\n",
    "input_features = pd.concat([residuals, energy_df['AEP_MW'], environment_df['value']], axis=1)\n",
    "\n",
    "# Scale input features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_input_features = scaler.fit_transform(input_features)\n",
    "\n",
    "# Define ANN model\n",
    "ann_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(scaled_input_features.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile ANN model\n",
    "ann_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train ANN model\n",
    "ann_model.fit(scaled_input_features, finance_df['close'], epochs=100, batch_size=32)\n",
    "\n",
    "# Generate forecasts using ANN model\n",
    "ann_forecast = ann_model.predict(scaled_input_features)[-10:]\n",
    "\n",
    "# Combine forecasts\n",
    "final_forecast = arima_forecast + ann_forecast\n",
    "\n",
    "# Evaluate performance\n",
    "actual_values = finance_df['close'][-10:]\n",
    "mae = mean_absolute_error(actual_values, final_forecast)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "print(\"Final Forecast:\")\n",
    "print(final_forecast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 594ms/step - loss: 0.2860 - val_loss: 0.2680\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2682 - val_loss: 0.2435\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2522 - val_loss: 0.2222\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2382 - val_loss: 0.2030\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2254 - val_loss: 0.1852\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2135 - val_loss: 0.1685\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2027 - val_loss: 0.1534\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1929 - val_loss: 0.1400\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1841 - val_loss: 0.1275\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1761 - val_loss: 0.1159\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1688 - val_loss: 0.1061\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1623 - val_loss: 0.0972\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1564 - val_loss: 0.0892\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1508 - val_loss: 0.0821\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1456 - val_loss: 0.0756\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1411 - val_loss: 0.0696\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1367 - val_loss: 0.0642\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1327 - val_loss: 0.0594\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1289 - val_loss: 0.0549\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1254 - val_loss: 0.0511\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1222 - val_loss: 0.0478\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1192 - val_loss: 0.0448\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1163 - val_loss: 0.0422\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1137 - val_loss: 0.0398\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1114 - val_loss: 0.0379\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1092 - val_loss: 0.0362\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1072 - val_loss: 0.0347\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1053 - val_loss: 0.0336\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1037 - val_loss: 0.0327\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1022 - val_loss: 0.0321\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1009 - val_loss: 0.0316\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0997 - val_loss: 0.0313\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0986 - val_loss: 0.0312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0977 - val_loss: 0.0312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0968 - val_loss: 0.0313\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0961 - val_loss: 0.0314\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0954 - val_loss: 0.0316\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0947 - val_loss: 0.0319\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0942 - val_loss: 0.0321\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0936 - val_loss: 0.0323\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0930 - val_loss: 0.0325\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0925 - val_loss: 0.0326\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0919 - val_loss: 0.0327\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0914 - val_loss: 0.0327\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0908 - val_loss: 0.0326\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0902 - val_loss: 0.0324\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0896 - val_loss: 0.0321\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0890 - val_loss: 0.0318\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0883 - val_loss: 0.0314\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0876 - val_loss: 0.0310\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0870 - val_loss: 0.0305\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0863 - val_loss: 0.0300\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0856 - val_loss: 0.0295\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0849 - val_loss: 0.0290\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0842 - val_loss: 0.0285\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0835 - val_loss: 0.0281\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0829 - val_loss: 0.0276\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0823 - val_loss: 0.0272\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0817 - val_loss: 0.0268\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0811 - val_loss: 0.0264\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0806 - val_loss: 0.0260\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0800 - val_loss: 0.0257\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0795 - val_loss: 0.0253\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0789 - val_loss: 0.0250\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0784 - val_loss: 0.0248\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0779 - val_loss: 0.0245\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0773 - val_loss: 0.0242\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0768 - val_loss: 0.0240\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0763 - val_loss: 0.0238\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0758 - val_loss: 0.0236\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0753 - val_loss: 0.0234\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0748 - val_loss: 0.0232\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0742 - val_loss: 0.0230\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0737 - val_loss: 0.0228\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0732 - val_loss: 0.0226\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0727 - val_loss: 0.0224\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0722 - val_loss: 0.0223\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0717 - val_loss: 0.0221\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0712 - val_loss: 0.0219\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0707 - val_loss: 0.0218\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0702 - val_loss: 0.0216\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0697 - val_loss: 0.0214\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0692 - val_loss: 0.0213\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0687 - val_loss: 0.0211\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0682 - val_loss: 0.0209\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0677 - val_loss: 0.0208\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0672 - val_loss: 0.0206\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0667 - val_loss: 0.0205\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0662 - val_loss: 0.0203\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0658 - val_loss: 0.0202\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0653 - val_loss: 0.0200\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0648 - val_loss: 0.0198\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0643 - val_loss: 0.0197\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0638 - val_loss: 0.0195\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0634 - val_loss: 0.0194\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0629 - val_loss: 0.0192\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0624 - val_loss: 0.0191\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0620 - val_loss: 0.0189\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0615 - val_loss: 0.0188\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0611 - val_loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n",
      "Forecasting predictions for finance dataset: [[0.3533595 ]\n",
      " [0.29544684]\n",
      " [0.33944103]\n",
      " [0.34756675]\n",
      " [0.35627934]\n",
      " [0.36460847]\n",
      " [0.37302467]\n",
      " [0.38142213]\n",
      " [0.3898237 ]\n",
      " [0.39822444]\n",
      " [0.40662527]\n",
      " [0.4150261 ]]\n",
      "Mean Absolute Error (MAE): 4107.0682626458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "finance_df = pd.read_csv(\"./Dataset/Monthly.csv\")\n",
    "energy_df = pd.read_csv(\"./Dataset/Hourly.csv\")\n",
    "environment_df = pd.read_csv(\"./Dataset/Daily.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_finance_data(data):\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data.set_index('Date', inplace=True)\n",
    "    data.fillna(method='ffill', inplace=True)\n",
    "    z_scores = (data - data.mean()) / data.std()\n",
    "    data = data[(z_scores < 3).all(axis=1)]\n",
    "    return data\n",
    "\n",
    "def preprocess_energy_data(data):\n",
    "    data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "    data.set_index('Datetime', inplace=True)\n",
    "    return data\n",
    "\n",
    "def preprocess_environment_data(data):\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data.set_index('date', inplace=True)\n",
    "    return data\n",
    "\n",
    "finance_df = preprocess_finance_data(finance_df)\n",
    "energy_df = preprocess_energy_data(energy_df)\n",
    "environment_df = preprocess_environment_data(environment_df)\n",
    "\n",
    "# ARIMA Model\n",
    "def fit_arima(data):\n",
    "    model = ARIMA(data, order=(2,2,1))\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=12)  # Example forecast for next 12 steps\n",
    "    return forecast\n",
    "\n",
    "# ANN Model\n",
    "def prepare_data_for_ann(data):\n",
    "    forecast = fit_arima(data)\n",
    "    X = np.array(forecast).reshape(-1, 1)\n",
    "    y = np.random.rand(len(X))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "# Build ANN Model\n",
    "def build_ann_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=input_shape),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train ANN Model\n",
    "def train_ann_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "    return model\n",
    "\n",
    "# Hybrid Model Integration\n",
    "def integrate_hybrid_model(ann_model, data):\n",
    "    # Fit ARIMA model and get forecast\n",
    "    forecast = fit_arima(data)\n",
    "    \n",
    "    # Scale forecast using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    forecast_scaled = scaler.fit_transform(np.array(forecast).reshape(-1, 1))\n",
    "    \n",
    "    # Predict using ANN model\n",
    "    hybrid_prediction = ann_model.predict(forecast_scaled)\n",
    "    \n",
    "    return hybrid_prediction\n",
    "\n",
    "# User input for choosing dataset\n",
    "dataset_choice = input(\"Choose dataset for forecasting (finance, energy, environment): \")\n",
    "\n",
    "# Perform forecasting based on user's choice\n",
    "if dataset_choice == \"finance\":\n",
    "    X_train, X_test, y_train, y_test = prepare_data_for_ann(finance_df['close'])\n",
    "    ann_model = build_ann_model(input_shape=(X_train.shape[1],))\n",
    "    trained_ann_model = train_ann_model(ann_model, X_train, y_train, X_test, y_test)\n",
    "    hybrid_prediction = integrate_hybrid_model(trained_ann_model, finance_df['close'])\n",
    "    actual_values = finance_df['close']\n",
    "    print(\"Forecasting predictions for finance dataset:\", hybrid_prediction)\n",
    "elif dataset_choice == \"energy\":\n",
    "    X_train, X_test, y_train, y_test = prepare_data_for_ann(energy_df['AEP_MW'])\n",
    "    ann_model = build_ann_model(input_shape=(X_train.shape[1],))\n",
    "    trained_ann_model = train_ann_model(ann_model, X_train, y_train, X_test, y_test)\n",
    "    hybrid_prediction = integrate_hybrid_model(trained_ann_model, energy_df['AEP_MW'])\n",
    "    actual_values = energy_df['AEP_MW']\n",
    "    print(\"Forecasting predictions for energy dataset:\", hybrid_prediction)\n",
    "elif dataset_choice == \"environment\":\n",
    "    X_train, X_test, y_train, y_test = prepare_data_for_ann(environment_df['value'])\n",
    "    ann_model = build_ann_model(input_shape=(X_train.shape[1],))\n",
    "    trained_ann_model = train_ann_model(ann_model, X_train, y_train, X_test, y_test)\n",
    "    hybrid_prediction = integrate_hybrid_model(trained_ann_model, environment_df['value'])\n",
    "    actual_values = environment_df['value']\n",
    "    print(\"Forecasting predictions for environment dataset:\", hybrid_prediction)\n",
    "else:\n",
    "    print(\"Invalid dataset choice. Please choose from finance, energy, or environment.\")\n",
    "\n",
    "# Evaluation\n",
    "mae = mean_absolute_error(actual_values[-len(hybrid_prediction):], hybrid_prediction)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 642ms/step - loss: 0.1538\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1452\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1371\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1295\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1224\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1157\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1095\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1037\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0983\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0935\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0892\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0855\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0823\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0798\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0777\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0763\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0753\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0748\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0746\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0748\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0751\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0754\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0758\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0760\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0761\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0761\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0759\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0756\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0752\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0748\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0742\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0737\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0732\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0728\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0723\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0720\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0717\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0714\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0712\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0711\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0709\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0708\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0706\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0705\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0704\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0703\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0701\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0700\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0699\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0697\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0695\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0694\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0692\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0690\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0689\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0687\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0686\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0684\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0683\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0682\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0680\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0679\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0678\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0677\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0676\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0675\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0674\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0673\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0671\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0671\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0670\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0669\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0668\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0667\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0666\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0665\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0664\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0663\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0662\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0662\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0661\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0660\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0659\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0658\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0658\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0657\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0656\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0656\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0655\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0654\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0654\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0653\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0652\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0652\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0651\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0650\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0650\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0649\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0649\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0648\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (3) does not match length of index (12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m     predictions_ann \u001b[38;5;241m=\u001b[39m generate_predictions_ann(X_train, y_train, X_test)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Combine predictions using ensemble method\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     ensemble_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mensemble_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions_arima\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_ann\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dataset_choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Generate predictions from ARIMA model\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     predictions_arima \u001b[38;5;241m=\u001b[39m generate_predictions_arima(energy_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAEP_MW\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[17], line 44\u001b[0m, in \u001b[0;36mensemble_predictions\u001b[1;34m(predictions_arima, predictions_ann, weights)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m]  \u001b[38;5;66;03m# Equal weighting for simplicity\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m ensemble_prediction \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictions_arima\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictions_ann\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensemble_prediction\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:102\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:6259\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6258\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m-> 6259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py:1327\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1325\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[1;32m-> 1327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:3223\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[1;34m(self, result, name)\u001b[0m\n\u001b[0;32m   3219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (res1, res2)\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;66;03m# We do not pass dtype to ensure that the Series constructor\u001b[39;00m\n\u001b[0;32m   3222\u001b[0m \u001b[38;5;66;03m#  does inference in the case where `result` has object-dtype.\u001b[39;00m\n\u001b[1;32m-> 3223\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3224\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   3226\u001b[0m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[0;32m   3227\u001b[0m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:461\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    459\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n\u001b[1;32m--> 461\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# create/copy the manager\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "File \u001b[1;32mc:\\Users\\97156\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (3) does not match length of index (12)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load and preprocess the data\n",
    "# (Assuming the dataset is already preprocessed as per previous examples)\n",
    "\n",
    "# Train ARIMA model\n",
    "def fit_arima(data):\n",
    "    model = ARIMA(data, order=(5,1,0))\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=12)  # Example forecast for next 12 steps\n",
    "    return forecast\n",
    "\n",
    "# Train ANN model\n",
    "def train_ann_model(X_train, y_train):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "    return model\n",
    "\n",
    "# Generate predictions from both models\n",
    "def generate_predictions_arima(data):\n",
    "    forecast = fit_arima(data)\n",
    "    return forecast\n",
    "\n",
    "def generate_predictions_ann(X_train, y_train, X_test):\n",
    "    model = train_ann_model(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "# Combine predictions using weighted average\n",
    "def ensemble_predictions(predictions_arima, predictions_ann, weights=None):\n",
    "    if weights is None:\n",
    "        weights = [0.5, 0.5]  # Equal weighting for simplicity\n",
    "    ensemble_prediction = (weights[0] * predictions_arima) + (weights[1] * predictions_ann)\n",
    "    return ensemble_prediction\n",
    "\n",
    "# User input for choosing dataset\n",
    "dataset_choice = input(\"Choose dataset (finance, energy, environment): \")\n",
    "\n",
    "# Load and preprocess the chosen dataset\n",
    "if dataset_choice == \"finance\":\n",
    "    # Generate predictions from ARIMA model\n",
    "    predictions_arima = generate_predictions_arima(finance_df['close'])\n",
    "    # Generate predictions from ANN model\n",
    "    predictions_ann = generate_predictions_ann(X_train, y_train, X_test)\n",
    "    # Combine predictions using ensemble method\n",
    "    ensemble_prediction = ensemble_predictions(predictions_arima, predictions_ann)\n",
    "elif dataset_choice == \"energy\":\n",
    "    # Generate predictions from ARIMA model\n",
    "    predictions_arima = generate_predictions_arima(energy_df['AEP_MW'])\n",
    "    # Generate predictions from ANN model\n",
    "    predictions_ann = generate_predictions_ann(X_train, y_train, X_test)\n",
    "    # Combine predictions using ensemble method\n",
    "    ensemble_prediction = ensemble_predictions(predictions_arima, predictions_ann)\n",
    "elif dataset_choice == \"environment\":\n",
    "    # Generate predictions from ARIMA model\n",
    "    predictions_arima = generate_predictions_arima(environment_df['value'])\n",
    "    # Generate predictions from ANN model\n",
    "    predictions_ann = generate_predictions_ann(X_train, y_train, X_test)\n",
    "    # Combine predictions using ensemble method\n",
    "    ensemble_prediction = ensemble_predictions(predictions_arima, predictions_ann)\n",
    "else:\n",
    "    print(\"Invalid dataset choice.\")\n",
    "\n",
    "# Evaluate ensemble prediction\n",
    "mae_ensemble = mean_absolute_error(actual_values[-len(ensemble_prediction):], ensemble_prediction)\n",
    "print(\"Mean Absolute Error (MAE) for ensemble model:\", mae_ensemble)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
